{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import pymfe\n",
    "import glob\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans \n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "cwd_back = os.path.dirname(cwd)\n",
    "data_path = os.path.join(cwd_back, 'tcc_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\Documents\\tcc_\\data\\Iris.csv\n",
      "C:\\Users\\danie\\Documents\\tcc_\\data\\Iris1.csv\n"
     ]
    }
   ],
   "source": [
    "data_list = os.path.join(data_path, 'data')\n",
    "files2upload_list = [item for item in os.listdir(data_list) if '.parquet' in item \\\n",
    "                              or '.csv' in item or '.data' in item]\n",
    "\n",
    "all_files = glob.glob(data_list + \"/*.csv\")\n",
    "\n",
    "files = []\n",
    "i = 0\n",
    "for file_ in all_files:\n",
    "    filepath_ = os.path.join(data_path, 'data', file_)\n",
    "    files.append(pd.read_csv(file_, index_col=None, header=0))\n",
    "    print(filepath_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris-setosa        50\n",
      "Iris-versicolor    50\n",
      "Iris-virginica     50\n",
      "Name: Species, dtype: int64\n",
      "Iris-setosa        50\n",
      "Iris-versicolor    50\n",
      "Iris-virginica     50\n",
      "Name: Species, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "for df in files:\n",
    "    print(df['Species'].value_counts())\n",
    "    x.append(df.iloc[:, [0, 1, 2, 3]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\envs\\tcc_\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:881: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Finding the optimum number of clusters for k-means classification\n",
    "from sklearn.cluster import KMeans\n",
    "wcss = []\n",
    "\n",
    "for i in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters = i, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 0)\n",
    "    kmeans.fit(x[0])\n",
    "    wcss.append(kmeans.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
