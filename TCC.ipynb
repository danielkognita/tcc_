{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import pymfe\n",
    "import glob\n",
    "import matplotlib.pyplot as plt \n",
    "#import seaborn as sns\n",
    "from sklearn.cluster import KMeans \n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "cwd_back = os.path.dirname(cwd)\n",
    "data_path = os.path.join(cwd_back, 'tcc_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2034560129119705\n"
     ]
    },
    {
     "ename": "AxisError",
     "evalue": "axis 0 is out of bounds for array of dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 46\u001b[0m\n\u001b[1;32m     39\u001b[0m df_std_lin \u001b[38;5;241m=\u001b[39m describe\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m#.dropna(axis=0, how='all')\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m#adicionando a lista de resultados\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m#print(df_std_lin)\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m#aplicando desvio padrão\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m df_std_lin \u001b[38;5;241m=\u001b[39m \u001b[43mdf_std_lin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m#ordenando delo maior desvio \u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m#df_std_lin = df_std_lin.sort_values()    \u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m#print(df_std_lin.rank())\u001b[39;00m\n\u001b[1;32m     53\u001b[0m files_lin\u001b[38;5;241m.\u001b[39mappend(df_std_lin\u001b[38;5;241m.\u001b[39mrank())   \n",
      "File \u001b[0;32m~/anaconda3/envs/requirements/lib/python3.8/site-packages/numpy/core/_methods.py:265\u001b[0m, in \u001b[0;36m_std\u001b[0;34m(a, axis, dtype, out, ddof, keepdims, where)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_std\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, ddof\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m    264\u001b[0m          where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 265\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43m_var\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mddof\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mddof\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m               \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, mu\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m    269\u001b[0m         ret \u001b[38;5;241m=\u001b[39m um\u001b[38;5;241m.\u001b[39msqrt(ret, out\u001b[38;5;241m=\u001b[39mret)\n",
      "File \u001b[0;32m~/anaconda3/envs/requirements/lib/python3.8/site-packages/numpy/core/_methods.py:200\u001b[0m, in \u001b[0;36m_var\u001b[0;34m(a, axis, dtype, out, ddof, keepdims, where)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_var\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, ddof\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m    197\u001b[0m          where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    198\u001b[0m     arr \u001b[38;5;241m=\u001b[39m asanyarray(a)\n\u001b[0;32m--> 200\u001b[0m     rcount \u001b[38;5;241m=\u001b[39m \u001b[43m_count_reduce_items\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;66;03m# Make this warning show up on top.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ddof \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m rcount \u001b[38;5;28;01mif\u001b[39;00m where \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m umr_any(ddof \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m rcount, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "File \u001b[0;32m~/anaconda3/envs/requirements/lib/python3.8/site-packages/numpy/core/_methods.py:76\u001b[0m, in \u001b[0;36m_count_reduce_items\u001b[0;34m(arr, axis, keepdims, where)\u001b[0m\n\u001b[1;32m     74\u001b[0m     items \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m axis:\n\u001b[0;32m---> 76\u001b[0m         items \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mshape[\u001b[43mmu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize_axis_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndim\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m     77\u001b[0m     items \u001b[38;5;241m=\u001b[39m nt\u001b[38;5;241m.\u001b[39mintp(items)\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;66;03m# TODO: Optimize case when `where` is broadcast along a non-reduction\u001b[39;00m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;66;03m# axis and full sum is more excessive than needed.\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \n\u001b[1;32m     82\u001b[0m     \u001b[38;5;66;03m# guarded to protect circular imports\u001b[39;00m\n",
      "\u001b[0;31mAxisError\u001b[0m: axis 0 is out of bounds for array of dimension 0"
     ]
    }
   ],
   "source": [
    "data_list = os.path.join(data_path, 'resultados')\n",
    "data_list_original = os.path.join(data_path, 'original')\n",
    "#files2upload_list = [item for item in os.listdir(data_list) if '.parquet' in item \\\n",
    "#                              or '.csv' in item or '.data' in item]\n",
    "\n",
    "all_files = glob.glob(data_list + \"/*.csv\")\n",
    "all_files_original = glob.glob(data_list_original + \"/*.csv\")\n",
    "\n",
    "\n",
    "#função normalização por min max\n",
    "def minmax_norm(df_input):\n",
    "    return (df_input - df_input.min()) / ( df_input.max() - df_input.min())\n",
    "    \n",
    "\n",
    "files_lin = []\n",
    "files_col = []\n",
    "files_orig = []\n",
    "i = 0\n",
    "j = 0\n",
    "for file_  in all_files:\n",
    "    #lendo arquivos com os resultados\n",
    "    filepath_ = os.path.join(data_path, 'data', file_)\n",
    "    \n",
    "    #lendo resultados\n",
    "    df = pd.read_csv(file_, sep = '\\t')\n",
    "    df = df.drop(['reducao', 'id_experimento'], axis=1)\n",
    "    \n",
    "    #aplicando normalização min max\n",
    "    df_minmax_norm = minmax_norm(df)\n",
    "    \n",
    "    df_minmax_norm = df_minmax_norm.std(axis= 0)\n",
    "    #tirar a media das medidas\n",
    "    describe = df_minmax_norm.describe()\n",
    "    print(describe.iloc[1])\n",
    "   # print(describe)\n",
    "    \n",
    "    #retirando os NAs\n",
    "    #print(describe)\n",
    "    df_std_lin = describe.iloc[1]\n",
    "    #.dropna(axis=0, how='all')\n",
    "    #adicionando a lista de resultados\n",
    "    \n",
    "    #print(df_std_lin)\n",
    "    \n",
    "    #aplicando desvio padrão\n",
    "    df_std_lin = df_std_lin.std(axis= 0)\n",
    "    \n",
    "    #ordenando delo maior desvio \n",
    "    #df_std_lin = df_std_lin.sort_values()    \n",
    "    #print(df_std_lin.rank())\n",
    "   \n",
    "    \n",
    "    files_lin.append(df_std_lin.rank())   \n",
    "    print(i,filepath_)\n",
    "    i=i+1\n",
    "    \n",
    "#for file_original in all_files_original:\n",
    "    #listando arquivos com medidas originais\n",
    "#    filepath_original_ = os.path.join(data_path, 'data', file_original)\n",
    "\n",
    "    #lendo medidas originais\n",
    "#    df_original = pd.read_csv(file_original, sep = '\\t')\n",
    "    #adicionando a lista de originais\n",
    "#    files_orig.append(df_original)\n",
    "\n",
    "\n",
    "#    print(j,filepath_original_)\n",
    "#    j = j+1\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=0\n",
    "for i in files_lin:\n",
    "    print(i)\n",
    "    #print(files_orig[x])\n",
    "    x=x+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in files_lin:\n",
    "    i.plot()\n",
    "    plt.show()\n",
    "#print(files_orig[11].plot())\n",
    "#columns ='attr_conc.max', 'attr_conc.mean', 'attr_conc.median', 'attr_conc.min', 'attr_conc.sd', 'attr_ent.max', 'attr_ent.mean', 'attr_ent.median', 'attr_ent.min', 'attr_ent.sd', 'attr_to_inst', 'cat_to_num', 'cor.max', 'cor.mean', 'cor.median', 'cor.min', 'cor.sd', 'cov.max', 'cov.mean', 'cov.median', 'cov.min', 'cov.sd', 'eigenvalues.max', 'eigenvalues.mean', 'eigenvalues.median', 'eigenvalues.min', 'eigenvalues.sd', 'g_mean.max', 'g_mean.mean', 'g_mean.median', 'g_mean.min', 'g_mean.sd', 'h_mean.max', 'h_mean.mean', 'h_mean.median', 'h_mean.min', 'h_mean.sd', 'inst_to_attr', 'iq_range.max', 'iq_range.mean', 'iq_range.median', 'iq_range.min', 'iq_range.sd', 'kurtosis.max', 'kurtosis.mean', 'kurtosis.median', 'kurtosis.min', 'kurtosis.sd', 'mad.max', 'mad.mean', 'mad.median', 'mad.min', 'mad.sd', 'max.max', 'max.mean', 'max.median', 'max.min', 'max.sd', 'mean.max', 'mean.mean', 'mean.median', 'mean.min', 'mean.sd', 'median.max', 'median.mean', 'median.median', 'median.min', 'median.sd', 'min.max', 'min.mean', 'min.median', 'min.min', 'min.sd', 'nr_attr', 'nr_bin', 'nr_cat', 'nr_cor_attr', 'nr_inst', 'nr_norm', 'nr_num', 'nr_outliers', 'num_to_cat', 'range.max', 'range.mean', 'range.median', 'range.min', 'range.sd', 'sd.max', 'sd.mean', 'sd.median', 'sd.min', 'sd.sd', 'skewness.max', 'skewness.mean', 'skewness.median', 'skewness.min', 'skewness.sd', 'sparsity.max', 'sparsity.mean', 'sparsity.median', 'sparsity.min', 'sparsity.sd', 't_mean.max', 't_mean.mean', 't_mean.median', 't_mean.min', 't_mean.sd', 'var.max', 'var.mean', 'var.median', 'var.min', 'var.sd') \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=0\n",
    "for i in files_lin:\n",
    "    #dados grafico reduzido\n",
    "    eixoXX = np.ones(files_lin[x].size)\n",
    "    #dados grafico original\n",
    "    eixoX = np.ones(files_orig[x].size)\n",
    "    #plotando grafico medidas reduzidas\n",
    "    plt.scatter(eixoXX, files_lin[x])\n",
    "    plt.show()\n",
    "\n",
    "    #plotando grafico com dados originais\n",
    "    #plt.scatter(eixoX, files_orig[x])\n",
    "    #plt.xlim([0,3])\n",
    "    #plt.show()\n",
    "    x=x+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m x \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m df \u001b[38;5;129;01min\u001b[39;00m \u001b[43mfiles\u001b[49m:\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m#print(df['Species'].value_counts())\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     x\u001b[38;5;241m.\u001b[39mappend(df\u001b[38;5;241m.\u001b[39miloc[:, [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m]]\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(x)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'files' is not defined"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "for df in files:\n",
    "    #print(df['Species'].value_counts())\n",
    "    x.append(df.iloc[:, [0, 1, 2, 3]].values)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding the optimum number of clusters for k-means classification\n",
    "from sklearn.cluster import KMeans\n",
    "wcss = []\n",
    "\n",
    "for i in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters = i, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 0)\n",
    "    kmeans.fit(x[0])\n",
    "    wcss.append(kmeans.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wcss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
